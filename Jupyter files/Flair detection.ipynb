{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='8kRfdrPdpbJe9Q',\n",
    "                     client_secret='qeSfFi6kizAdurAFL790ZhQL_uM',\n",
    "                     user_agent='Anukriti Jain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_string(value):\n",
    "    return \"%s\"%value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\", \"AMA\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "posts = []\n",
    "subreddit = reddit.subreddit('India')\n",
    "for flair in flairs:\n",
    "    for post in subreddit.search(flair, limit=300):\n",
    "        count = 1\n",
    "        post.comments.replace_more(limit=None)\n",
    "        comment = \"\"\n",
    "        for top_level_comment in post.comments.list():\n",
    "            if(count<=5):\n",
    "                comment = comment + \" \" + top_level_comment.body\n",
    "            else: break\n",
    "            count+=1\n",
    "        posts.append([post.id, flair, post.title, post.author, post.url, post.num_comments, post.selftext, datetime.fromtimestamp(post.created), comment])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.DataFrame(posts, columns=['id', 'flair','title', 'author ','url', 'num_comments', 'body', 'timestamp', 'comments'])\n",
    "posts.drop_duplicates(subset='id', keep = False, inplace=True)\n",
    "posts.to_csv('Final_reddit_India.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Final_reddit_India.csv')\n",
    "df.to_json('Final_reddit_India.json', orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "#import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopwords_eng = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "#d = enchant.Dict(\"en_US\")\n",
    "\n",
    "def getStemmedText(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    post = text\n",
    "    #post = text.split()\n",
    "    #post = \"\"\n",
    "    #for word in new_text:\n",
    "    #   if d.check(word)==True:\n",
    "    #        post = post + \" \" + word\n",
    "    \n",
    "    tokens = tokenizer.tokenize(post)\n",
    "    new_tokens = []\n",
    "    stemmed_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token not in stopwords_eng:\n",
    "            new_tokens.append(token)\n",
    "    \n",
    "    for token in new_tokens:\n",
    "        stemmed_tokens.append(stemmer.stem(token))\n",
    "        \n",
    "    cleaned_text = ' '.join(stemmed_tokens)\n",
    "    return cleaned_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['title','url','body','comments']\n",
    "\n",
    "X = posts[features]\n",
    "Y = posts.flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['title'] = X['title'].apply(getStemmedText).apply(to_string)\n",
    "X['body'] = X['body'].apply(getStemmedText).apply(to_string)\n",
    "X['comments'] = X['comments'].apply(getStemmedText).apply(to_string)\n",
    "X['url'] = X['url'].apply(getStemmedText).apply(to_string)\n",
    "#X['author '] = X['author '].apply(to_string)\n",
    "\n",
    "combined = X[\"title\"] + X[\"comments\"] + X[\"url\"]+X[\"body\"]#+ X[\"author \"]\n",
    "X = X.assign(combined = combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, Y, test_size=0.2, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MultiNomial Naive Bayes:  63.67432150313152\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.89      0.55      0.68        44\n",
      "     Non-Political       0.55      0.43      0.48        49\n",
      "     [R]eddiquette       0.42      0.71      0.52        38\n",
      "         Scheduled       0.83      0.73      0.78        55\n",
      "       Photography       1.00      0.31      0.47        36\n",
      "Science/Technology       0.48      0.75      0.58        28\n",
      "          Politics       0.75      0.60      0.67        50\n",
      "  Business/Finance       0.62      0.67      0.64        51\n",
      "    Policy/Economy       0.64      0.70      0.67        43\n",
      "            Sports       0.59      0.80      0.68        46\n",
      "              Food       0.73      0.88      0.80        34\n",
      "               AMA       0.00      0.00      0.00         5\n",
      "\n",
      "          accuracy                           0.64       479\n",
      "         macro avg       0.62      0.59      0.58       479\n",
      "      weighted avg       0.68      0.64      0.63       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', MultinomialNB()),\n",
    "                ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of MultiNomial Naive Bayes: \",accuracy_score(y_test, y_pred)*100)\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression:  74.73903966597078\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.89      0.70      0.78        44\n",
      "     Non-Political       0.68      0.69      0.69        49\n",
      "     [R]eddiquette       0.58      0.76      0.66        38\n",
      "         Scheduled       0.85      0.80      0.82        55\n",
      "       Photography       0.84      0.72      0.78        36\n",
      "Science/Technology       0.63      0.68      0.66        28\n",
      "          Politics       0.79      0.68      0.73        50\n",
      "  Business/Finance       0.69      0.75      0.72        51\n",
      "    Policy/Economy       0.75      0.70      0.72        43\n",
      "            Sports       0.71      0.89      0.79        46\n",
      "              Food       0.94      0.88      0.91        34\n",
      "               AMA       0.67      0.40      0.50         5\n",
      "\n",
      "          accuracy                           0.75       479\n",
      "         macro avg       0.75      0.72      0.73       479\n",
      "      weighted avg       0.76      0.75      0.75       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3))),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', LogisticRegression(n_jobs=-1, C=1e5, random_state=18)),\n",
    "                 ])\n",
    "logr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logr.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of Logistic Regression: \", accuracy_score(y_pred, y_test)*100)\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier:  81.00208768267223\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.87      0.77      0.82        44\n",
      "     Non-Political       0.77      0.88      0.82        49\n",
      "     [R]eddiquette       0.77      0.79      0.78        38\n",
      "         Scheduled       0.89      0.76      0.82        55\n",
      "       Photography       0.83      0.83      0.83        36\n",
      "Science/Technology       0.67      0.79      0.72        28\n",
      "          Politics       0.84      0.74      0.79        50\n",
      "  Business/Finance       0.70      0.82      0.76        51\n",
      "    Policy/Economy       0.89      0.74      0.81        43\n",
      "            Sports       0.82      0.91      0.87        46\n",
      "              Food       0.89      0.94      0.91        34\n",
      "               AMA       1.00      0.40      0.57         5\n",
      "\n",
      "          accuracy                           0.81       479\n",
      "         macro avg       0.83      0.78      0.79       479\n",
      "      weighted avg       0.82      0.81      0.81       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "  \n",
    "randfr = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', RandomForestClassifier(n_estimators = 500, random_state = 18)),\n",
    "                 ])\n",
    "randfr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = randfr.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of Random Forest Classifier: \", accuracy_score(y_pred, y_test)*100)\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP Classifier:  51.98329853862212\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.86      0.41      0.55        44\n",
      "     Non-Political       0.30      0.57      0.39        49\n",
      "     [R]eddiquette       0.43      0.61      0.51        38\n",
      "         Scheduled       0.84      0.65      0.73        55\n",
      "       Photography       0.41      0.25      0.31        36\n",
      "Science/Technology       0.50      0.43      0.46        28\n",
      "          Politics       0.74      0.58      0.65        50\n",
      "  Business/Finance       0.43      0.39      0.41        51\n",
      "    Policy/Economy       0.54      0.65      0.59        43\n",
      "            Sports       0.66      0.41      0.51        46\n",
      "              Food       0.46      0.76      0.58        34\n",
      "               AMA       1.00      0.20      0.33         5\n",
      "\n",
      "          accuracy                           0.52       479\n",
      "         macro avg       0.60      0.49      0.50       479\n",
      "      weighted avg       0.58      0.52      0.52       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "  \n",
    "mlp = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', MLPClassifier(hidden_layer_sizes=(30,20,20), random_state=18)),\n",
    "                 ])\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of MLP Classifier: \", accuracy_score(y_pred, y_test)*100)\n",
    "print(classification_report(y_test, y_pred,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Support Vector Classifier:  72.44258872651356\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.88      0.64      0.74        44\n",
      "     Non-Political       0.49      0.76      0.59        49\n",
      "     [R]eddiquette       0.54      0.74      0.62        38\n",
      "         Scheduled       0.89      0.73      0.80        55\n",
      "       Photography       0.85      0.61      0.71        36\n",
      "Science/Technology       0.76      0.68      0.72        28\n",
      "          Politics       0.78      0.70      0.74        50\n",
      "  Business/Finance       0.71      0.80      0.75        51\n",
      "    Policy/Economy       0.85      0.67      0.75        43\n",
      "            Sports       0.71      0.87      0.78        46\n",
      "              Food       0.93      0.76      0.84        34\n",
      "               AMA       1.00      0.40      0.57         5\n",
      "\n",
      "          accuracy                           0.72       479\n",
      "         macro avg       0.78      0.70      0.72       479\n",
      "      weighted avg       0.76      0.72      0.73       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer(ngram_range=(1,3))),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', SVC(kernel ='linear', random_state=18)),\n",
    "                ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of Support Vector Classifier: \", accuracy_score(y_test, y_pred)*100)\n",
    "print(classification_report(y_test, y_pred, target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'model.sav'\n",
    "pickle.dump(randfr, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:renv] *",
   "language": "python",
   "name": "conda-env-renv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
